{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPrAYAyh8iccb27lcWcZ1Xg"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"mRT8-SZK1RBX"},"outputs":[],"source":["# General Libararies\n","import time\n","import os, sys\n","import numpy as np\n","import cv2\n","from tqdm import tqdm\n","import random\n","import importlib\n","import seaborn as sns\n","import pandas as pd\n","import array as arr\n","\n","# TensorFlow and tf.keras\n","import tensorflow as tf\n","from tensorflow import keras\n","import tensorflow.keras\n","\n","# Layers, loss, optimzer, model \n","from tensorflow.keras.layers import *\n","from tensorflow.keras.models import *\n","from tensorflow.keras import losses\n","from tensorflow.keras.optimizers import *\n","from tensorflow.keras import datasets, layers, models,losses\n","from keras.layers import Activation, Dense\n","from tensorflow.keras.models import Model\n","\n","# sklearn\n","from sklearn.preprocessing import LabelBinarizer\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import multilabel_confusion_matrix,roc_auc_score,confusion_matrix\n","import sklearn.metrics as metrics\n","\n","# Google Drive\n","from google.colab import files\n","from google.colab import drive\n","\n","# Plotting \n","import matplotlib.image as mpimg\n","import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","import plotly.graph_objects as go\n","from matplotlib import figure\n","from plotly.subplots import make_subplots\n","from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n","from sklearn.metrics import plot_confusion_matrix\n","\n","# image processing \n","**Loading Libraries**\n","from skimage import io\n","from keras.preprocessing.image import ImageDataGenerator \n","from keras.utils.vis_utils import plot_model\n","from tensorflow.keras.preprocessing.image import load_img\n","\n","# Imports PIL module \n","from PIL import Image\n","# inception\n","#https://keras.io/api/applications/#usage-examples-for-image-classification-models\n","from keras.applications.inception_v3 import InceptionV3\n","\n","#https://stackoverflow.com/questions/49471467/keras-implementation-of-inception-v3-does-not-have-the-bn-auxillary\n","\n","#Add Callbacks, e.g. ModelCheckpoints, earlystopping, csvlogger.\n","from keras.callbacks import ModelCheckpoint, EarlyStopping, CSVLogger\n","from pickle import TRUE\n","\n","# to initialize the random number generator.\n","import random\n","np.random.seed(1)\n","random.seed(1)\n","tensorflow.random.set_seed(1)\n","tf.random.set_seed(1)\n","tf.keras.utils.set_random_seed(1)   \n","#tf.config.experimental.enable_op_determinism()\n","tf.keras.backend.set_image_data_format('channels_last')\n","\n","# for Time claculiting \n","from timeit import default_timer as timer\n","from psutil import virtual_memory"]},{"cell_type":"markdown","source":["**GPU-Beschleuniger zu aktiviere/**\n","**Erweiterter RAM**"],"metadata":{"id":"ou5Xv_U15AOx"}},{"cell_type":"code","source":["gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Not connected to a GPU')\n","else:\n","  print(gpu_info)\n","\n","ram_gb = virtual_memory().total / 1e9\n","print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n","print(virtual_memory().total)\n","if ram_gb < 20:\n","  print('Not using a high-RAM runtime')\n","else:\n","  print('You are using a high-RAM runtime!')"],"metadata":{"id":"NwG7KOFf498f"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Mount Google Drive**"],"metadata":{"id":"7x4XHJAq5OR5"}},{"cell_type":"code","source":["drive.mount('/content/drive')\n"],"metadata":{"id":"6CxRhHNV5P-N"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","**load data**"],"metadata":{"id":"1--gr6cU5T_M"}},{"cell_type":"code","source":["# https://www.kaggle.com/datasets/masoudnickparvar/brain-tumor-mri-dataset/download\n","! unzip /content/drive/MyDrive/Training_Neronal_Network/archive.zip\n","# list all images \n","training_loc = 'Training/'\n","testing_loc  = 'Testing/'\n","notumor_loc=os.listdir('./Training/notumor')\n","pituitary_loc=os.listdir('./Training/pituitary')\n","glioma_loc=os.listdir('./Training/glioma')\n","meningioma_loc=os.listdir('./Training/meningioma')\n","target_labels = os.listdir(training_loc)"],"metadata":{"id":"---aMqDB5VnG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Connect to Lib /my_models function**"],"metadata":{"id":"08qFbsoJE40y"}},{"cell_type":"code","source":["sys.path.append('../content/drive/MyDrive/Funktionen')\n","#sys.path.append('../content/drive/MyDrive/Funktionen/my.py') -->\n","import importlib  \n","from lib import *\n","from my_models import *\n","import lib \n","import my_models \n","#to update changing \n","importlib.reload(lib) \n","importlib.reload(my_models)"],"metadata":{"id":"_mtlqfOdE4lG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Connect to Libfunction/my_models**\n","**Image generator**"],"metadata":{"id":"wRJMIKSp5cVJ"}},{"cell_type":"code","source":["# return image generator \n","# https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html\n","#to know how to define the input_shape in  InceptionV3 (150, 150, 3)\n","training_loc_target_size=print_max_min_dim(training_loc) \n","testing_locc_target_size=print_max_min_dim(testing_loc)\n","targetSize = (150, 150) #input_shape\n","target_labels = [\"glioma\", \"meningioma\", \"notumor\", \"pituitary\"]\n","# create image generator \n","train_gen, val_gen = img_gen(training_loc,target_labels,targetSize = targetSize)\n","**Plot Data**\n","#to plot dat\n","image_folder= ['glioma', 'meningioma', 'notumor', 'pituitary']\n","plt.figure(1)\n","plot_data_distribution_training(image_folder,training_loc)\n","plt.figure(2)\n","plot_data_distribution_testing(image_folder,testing_loc)"],"metadata":{"id":"lNfp6ig-5eHW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Build Inception V3 Model**"],"metadata":{"id":"d5cteVdW5lWL"}},{"cell_type":"code","source":["# https://keras.io/examples/vision/image_classification_from_scratch/\n","#((kernel_size)*stride+1)*filters)\n","from keras.applications.inception_v3 import InceptionV3\n","def modell_erstellen():\n","    tf.keras.backend.set_image_data_format('channels_last')\n","    conv_InceptionV3 =   InceptionV3(include_top=False,weights='imagenet',\n","                                     input_shape=(150,150,3))# https://image-net.org/challenges/LSVRC/ https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8530098/\n","    for layer in conv_InceptionV3.layers:\n","              layer.trainable = False\n","\n","    # Create a new 'top' of the model\n","    top_of_model = conv_InceptionV3.output\n","    top_of_model = Flatten(name=\"flatten\")(top_of_model) # multidimensional output and plan to make it linear so it may be sent onto a Dense layer\n","    top_of_model = Dense(4096, activation='relu')(top_of_model)\n","    top_of_model = Dropout(0.1)(top_of_model) # reducing too much connection between characteristics by lowering the weights (nodes) at a probability  https://arxiv.org/pdf/1207.0580.pdf\n","    output_layer = Dense(4, activation='softmax')(top_of_model) # the last Layer 4 classes \n","\n","    # Set up a new layer at the top of the model that is fully interconnected.\n","    model = Model(inputs=conv_InceptionV3.input, outputs=output_layer)\n","    return model"],"metadata":{"id":"fluFWzri5l2S"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Hyperparameters Searching space**"],"metadata":{"id":"DNgmiVHE5xop"}},{"cell_type":"code","source":["batch_sizes = [ 8, 16, 32, 64, 128] #  NUM_SAMPLES * SIZE_OF_SAMPLE.\n","decay_rate=[1,10,100,1000,10000]\n","learning_rate=0.000001\n","epochs_count = 100\n","beta_2=[0.99, 0.999, 0.9999]\n","# the models name \n","name=['eins','zwei','drei','vier','funf']\n","decay_rate_name=['1e-06', '1e-05',' 0.0001', '0.001','0.01']\n","batch_sizes_name=['8' ,'16' ,'32' ,'64' ,'128']\n","beta_2_name=['0.99', '0.999', '0.9999']"],"metadata":{"id":"-BO-X9xw5o2a"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**to make an new model with neu Wights**"],"metadata":{"id":"OdwtT-Ou52_v"}},{"cell_type":"code","source":["model = modell_erstellen()\n","model.save_weights('../content/drive/MyDrive/Inception/')"],"metadata":{"id":"x_sgsi0I55f5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Compile the Model/Train Model/Save model to Google Drive**\n"," + (1) to investigate the Parameter  learn rate changing\n"," + (2) to investigate the Parameter Batch Sizes changing \n"," + (3) to investigate the Parameter Momentum β2 s changing"],"metadata":{"id":"SNC_2Wmw5-zr"}},{"cell_type":"code","source":["\n","#(1) to investigate the Parameter  learn rate changing\n","experement=[1,2,3]\n","batch_size=32\n","train_gen, val_gen = img_gen(training_loc,target_labels, targetSize, batch_size=batch_size)\n","for h in range (len(experement)):\n","  times = np.zeros((len(decay_rate), 2),dtype=object)\n","  k=0\n","  batch_size=32\n","  beta_1=0.9 \n","  beta_2=0.999\n","  for i in range(len(decay_rate)):\n","      # The first iteration of the loop will be lrate_changing = 0.000001*1\n","      model = modell_erstellen()\n","      model.load_weights('../content/drive/MyDrive/Inception/')\n","      lrate_changing = learning_rate * decay_rate[i]  \n","      # train_gen, val_gen = img_gen(training_loc,target_labels, targetSize, batch_size=batch_size)\n","      History_model_basic, t_end =model_compiler(model, val_gen, train_gen, lrate_changing, beta_1, beta_2, batch_size, epochs_count, name[i],experement[h]) \n","      # to save the Time after Training \n","      times[k, 0] = t_end # (1)\n","      times[k,1]=str('lrate_changing:'+str(float(lrate_changing))+'')  # (1)\n","      k=k+1\n","      del model\n","\n","  # to save the training time after training prozess\n","  pd.DataFrame(times).to_csv(\"../content/drive/MyDrive/Hyperparameters\"+str(experement[h])+\"/Inception_lrate_changing.csv\""],"metadata":{"id":"sfg-VF4O5_eb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# (2) to investigate the Parameter Batch Sizes changing\n","# when the Batch Sizes ∈ batch_sizes = [ 8, 16, 32, 64, 128] is changed  but still  β1, β2 , learning_rate are constant \n","# This loop will run 5  times for number of hyperparameters\n","experement=[1,2,3]\n","batch_sizes=[ 8, 16, 32, 64, 128]\n","# to make a Matrix with same lengeth from batch_sizes , decay_rate or  β2 for to save the Training time \n","for h in range (len(experement)):\n","\n","  times = np.zeros((len(batch_sizes), 2),dtype=object)\n","  k=0\n","  lrate_changing =0.00001\n","  beta_1=0.9 \n","  beta_2=0.999\n","  for i in range(len(batch_sizes)):\n","\n","      batch_size=batch_sizes[i]\n","      model = modell_erstellen()\n","      model.load_weights('../content/drive/MyDrive/Inception/')\n","      # be careful when selecting which parameters to examine (1),(2),(3) , re-comment the constante parameters learning_rate , Batch Size, β1 ,β2,lrate_changing\n","      # the below function give back the History of Model and the Training time \n","      \n","\n","      # train_gen, val_gen = img_gen(training_loc,target_labels, targetSize, batch_size=batch_size)\n","      History_model_basic, t_end =model_compiler(model, val_gen, train_gen, lrate_changing, beta_1, beta_2, batch_size, epochs_count, name[i],experement[h]) \n","\n","      # to save the Time after Training \n","      times[k, 0] = t_end # (2)\n","      times[k,1]=str('batch_size:'+str(batch_sizes[i])+'') # (2) \n","      k=k+1\n","      del model\n","  # to save the training time after  \n","  pd.DataFrame(times).to_csv(\"../content/drive/MyDrive/Hyperparameters\"+str(experement[h])+\"/Inception_batch_changing.csv\")"],"metadata":{"id":"5Pq6JJjQ6FGM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# (3) to investigate the Parameter Momentum β2 s changing\n","# when the β2 ∈ [0.99, 0.999, 0.9999] is changed but still  β1 , learning_rate , Batch Size are constant \n","# This loop will run 3  times for number of hyperparameters\n","\n","experement=[1,2]\n","for h in range (len(experement)):\n","  k=0\n","  beta_2=[0.99, 0.999, 0.9999]\n","  times = np.zeros((len(beta_2), 2),dtype=object)\n","  lrate_changing =0.00001\n","  batch_size =128\n","  for i in range(len(beta_2)):\n","      beta_1=0.9\n","      model = modell_erstellen()\n","      model.load_weights('../content/drive/MyDrive/Inception/')\n","      # be careful when selecting which parameters to examine (1),(2),(3) , re-comment the constante parameters learning_rate , Batch Size, β1 ,β2,lrate_changing\n","      # the below function give back the History of Model and the Training time\n","\n","      History_model_basic,t_end=model_compiler(model,val_gen,train_gen,lrate_changing,beta_1, beta_2[i],batch_size,epochs_count,name[i],experement[h])\n","\n","      # to save the Time after Training \n","      times[k, 0] = t_end # (3)\n","\n","      times[k,1]=str('beta_2:'+str(float(beta_2[i]))+'') # (3)\n","\n","      k=k+1\n","      del model\n","  # to save the training time after  \n","  pd.DataFrame(times).to_csv(\"../content/drive/MyDrive/Hyperparameters\"+str(experement[h])+\"/Inception_beta_changing.csv\")"],"metadata":{"id":"0Zt46h4h6K31"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**After Save Models/Load all**"],"metadata":{"id":"rS_EVNXB6Sft"}},{"cell_type":"code","source":["models_numbers= decay_rate# (1) decay_rate ,(2) batch_sizes or (3) beta_2  muss to be the same number of models \n","json_h5_pathfile='../content/drive/MyDrive/Hyperparameters/'\n","speicher=loading_models(json_h5_pathfile,name,models_numbers)"],"metadata":{"id":"yjQfm43T6RyX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#this function to load all models from drive the first Parameter is the filepath the sekund is the name=['eins','zwei','drei','vier','funf']\n","#speicher here is a placeholder to save all models in it, all models will be uploaded\n","def loading_models(json_h5_pathfile,name,models_numbers):\n","  speicher= [None] * len(models_numbers)\n","  for i in range(len(models_numbers)):\n","    # load json and create model \n","\n","    json_file = open(''+json_h5_pathfile+'/model_'+name[i]+'.json','r')\n","\n","    loaded_model_json= json_file.read()\n","    json_file.close()\n","    loaded_model = model_from_json(loaded_model_json)\n","    speicher[i]=loaded_model\n","\n","    # load weights into new model\n","    loaded_model.load_weights(\"\"+json_h5_pathfile+\"/model_\"+name[i]+\".h5\")\n","    print(\"Loaded model from disk\")\n","  return speicher"],"metadata":{"id":"on22z0PD6meg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","**Testing the Model**"],"metadata":{"id":"FlevBV996XnH"}},{"cell_type":"code","source":["#def loading_models(json_h5_pathfile, name, models_numbers):\n","#data Aug for Testing\n","Generator_test = ImageDataGenerator(rescale = 1./255,shear_range=0.2)\n","test_gen      = Generator_test.flow_from_directory(testing_loc,\n","# resizing testing images to (min(heights), min(widths)) in both trainining and testing sets\n","target_size = (150,150),\n","color_mode = 'rgb',\n","classes = target_labels,\n","class_mode = 'categorical',\n","batch_size = 1,\n","shuffle = False,subset = None)"],"metadata":{"id":"fbJVWnD-6X8s"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Plot the accuracy loss val_accuracy val_loss**\n"," + (1) to investigate the Parameter  learn rate changing\n"," + (2) to investigate the Parameter Batch Sizes changing \n"," + (3) to investigate the Parameter Momentum β2 s changing"],"metadata":{"id":"ummy8GRm6rCl"}},{"cell_type":"code","source":["# (1) to investigate the Parameter  learn rate changing\n","# when the learn rate ∈ 0.000001* [1,10,100,1000,10000] is changed and  but still  β1, β2 ,  Batch Size are constant  \n","\n","csv_pathfile_plot_acc_loss='../content/drive/MyDrive/Hyperparameters3/model_'\n","batch_sizes=32\n","decay_rates =[1,10,100,1000,10000]\n","plot_acc_loss_changed_learnrate(csv_pathfile_plot_acc_loss,name,batch_sizes, decay_rates)\n","\n","json_h5_pathfile='../content/drive/MyDrive/Hyperparameters3/'\n","\n","speicher = loading_models(json_h5_pathfile,name,decay_rates)\n","classification_report_testing_confusion_matrix_learnrate(json_h5_pathfile,speicher,name,batch_sizes,decay_rates,test_gen,target_labels)\n","csv_pathfile_time = pd.read_csv('/content/drive/MyDrive/Hyperparameters3/Inception_lrate_changing.csv')\n","save_loc='/content/drive/MyDrive/Hyperparameters3/'\n","changed_hyperparameter_name='learning rate'#\n","values_of_parameter=decay_rate_name \n","plot_training_time(csv_pathfile_time ,save_loc,values_of_parameter,changed_hyperparameter_name)"],"metadata":{"id":"39c8SBzQ6fFz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# (2) to investigate the Parameter Batch Sizes changing\n","json_h5_pathfile='../content/drive/MyDrive/Hyperparameters3/'\n","batch_sizes=[8,16,32, 64, 128]\n","learning_rate =0.00001\n","speicher = loading_models(json_h5_pathfile,name,batch_sizes)\n","classification_report_testing_confusion_matrix_batchsize(json_h5_pathfile,speicher,name,batch_sizes,learning_rate,test_gen,target_labels)\n","csv_pathfile_plot_acc_loss='/content/drive/MyDrive/Hyperparameters3/model_'\n","\n","plot_acc_loss_changed_batchsize(csv_pathfile_plot_acc_loss,name,batch_sizes,learning_rate)\n","csv_pathfile_time = pd.read_csv('/content/drive/MyDrive/Hyperparameters3/Inception_batch_changing.csv')\n","save_loc='/content/drive/MyDrive/Hyperparameters3/'\n","changed_hyperparameter_name='Batch Size'#\n","values_of_parameter=batch_sizes_name\n","plot_training_time(csv_pathfile_time,save_loc,values_of_parameter,changed_hyperparameter_name)"],"metadata":{"id":"06K3Hyne6wSs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# (3) to investigate the Parameter Momentum β2 s changing\n","# when the β2 ∈ [0.99, 0.999, 0.9999] is changed but still  β1 , learning_rate , Batch Size are constant \n","csv_pathfile_plot_acc_loss='../content/drive/MyDrive/Hyperparameters2/model_'\n","learning_rate=0.00001\n","batch_sizes=128\n","beta_1=0.9\n","beta_2=[0.99, 0.999, 0.9999]\n","plot_acc_loss_changed_beta_2(csv_pathfile_plot_acc_loss,name,batch_sizes,learning_rate,beta_1,beta_2)\n","json_h5_pathfile='../content/drive/MyDrive/Hyperparameters2/'\n","speicher =loading_models(json_h5_pathfile,name,beta_2)\n","classification_report_testing_confusion_matrix_beta_2(json_h5_pathfile,speicher,name,batch_sizes,learning_rate,beta_1,beta_2, test_gen,target_labels)\n","csv_pathfile_time = pd.read_csv('/content/drive/MyDrive/Saved_training1/InceptionV3/beta_2/Inception_beta_changing.csv')\n","save_loc='/content/drive/MyDrive/Saved_training1/InceptionV3/beta_2/'\n","changed_hyperparameter_name='Momentum β2'#\n","values_of_parameter=beta_2_name\n","plot_training_time(csv_pathfile_time,save_loc,values_of_parameter,changed_hyperparameter_name)"],"metadata":{"id":"h3-1Kstx7NNn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["experement=[1,2,3]\n","mittelwert=np.zeros((len(experement), 1),dtype=object)\n","\n","csv_pathfile_plot_acc_loss='/content/drive/MyDrive/Saved_training1/Basic/lrate'\n","k=2   #model_type eins, zwei ..\n","for h in range (len(experement)):\n","  df = pd.read_csv(''+csv_pathfile_plot_acc_loss+''+str(experement[h])+'/model_'+name[k]+'.csv')\n","  dfx=df['epoch']\n","  dfval_loss=df['val_loss']\n","  mittelwert[h]=round(dfval_loss[dfx.iat[-1]],2)\n","print(mittelwert)"],"metadata":{"id":"NJVoNtX-7fdq"},"execution_count":null,"outputs":[]}]}